# Security Policy for dreampipe

## Introduction

`dreampipe` is a tool designed to integrate the capabilities of Large Language Models (LLMs) with the Unix shell environment. It allows processing command output and transforming data using natural language prompts, either ad-hoc or via reusable "natural language scripts."

This document outlines known security risks, mitigation strategies, best practices for users, and procedures for reporting vulnerabilities. While `dreampipe` itself does not execute LLM-generated code, interacting with LLMs still presents security considerations users should be aware of.

## Reporting Vulnerabilities

We take security seriously. If you discover a security vulnerability in `dreampipe`, please report it privately to ensure responsible disclosure. Do **not** create a public GitHub issue for security vulnerabilities.

Please report vulnerabilities via [**Specify preferred reporting method here - e.g., GitHub Security Advisories if enabled, or a dedicated private email address like security@yourdomain.com**].

We aim to acknowledge receipt of vulnerability reports within [Specify timeframe, e.g., 48 hours] and will work with you to understand and address the issue.

## Key Security Risks

Interacting with LLMs involves several risks, many highlighted by resources like the [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/). Key risks for `dreampipe` include:

1.  **Prompt Injection (LLM01):**
    *   **Description:** Maliciously crafted prompts (ad-hoc or in saved `dreampipe` scripts) or manipulated input data piped into `dreampipe` could trick the LLM into performing unintended actions or generating harmful/undesirable output. This includes *indirect prompt injection*, where instructions hidden in the input data (e.g., log files, command output) are processed by the LLM.
    *   **Impact:** Generation of misleading, offensive, or malicious textual output; information disclosure from the input data; denial of service to the LLM.

2.  **Sensitive Information Disclosure (LLM06):**
    *   **Description:**
        *   **Data to LLM:** Any data piped into `dreampipe` is sent to the configured LLM API (unless using a local LLM like Ollama). Piping sensitive data (secrets, personal info, proprietary code) exposes it to the LLM provider.
        *   **Data from LLM:** The LLM might inadvertently reveal sensitive information from its training data in its output, or be tricked via prompt injection into revealing details about the input data.
    *   **Impact:** Confidentiality breaches, privacy violations.

3.  **Denial of Service (LLM04 - Model & Application DoS):**
    *   **Description:**
        *   **Input Size:** Processing extremely large inputs piped to `dreampipe` can exhaust memory, as input is currently read fully before processing.
        *   **API Costs/Limits:** Malicious or poorly formed prompts could lead to excessive LLM API calls, incurring costs or hitting rate limits.
        *   **Resource Exhaustion:** Prompts requesting very complex transformations can cause high CPU usage by the LLM or `dreampipe` itself.
    *   **Impact:** Service unavailability, high operational costs.

4.  **Supply Chain Vulnerabilities (LLM05):**
    *   **Description:** Vulnerabilities in the chosen LLM provider, `dreampipe`'s own dependencies (e.g., libraries for HTTP), or the build environment could be exploited.
    *   **Impact:** Varies widely, potentially leading to any of the risks above.

5.  **Over-reliance on LLM Output / Misinformation (LLM09):**
    *   **Description:** Users might implicitly trust the output generated by `dreampipe`. LLMs can make mistakes ("hallucinate"), generate biased content, or produce subtly flawed information.
    *   **Impact:** Acting on incorrect information, making poor decisions based on flawed analysis, propagation of misinformation. The LLM might also generate text that *looks like* code or commands; if a user manually copies and executes this, it carries the same risks as running any untrusted script.

6.  **Insecure Output Handling (User-Side):**
    *   **Description:** While `dreampipe` itself doesn't execute LLM-generated code, an LLM might produce output that *suggests* commands or code snippets. If a user uncritically copies and pastes this output into their shell or a script, it could lead to unintended consequences.
    *   **Impact:** Similar to running any untrusted code: data loss, system modification, security breaches, depending on the commands executed.

## Security Best Practices for Users

Using `dreampipe` safely requires vigilance:

1.  **Be Mindful of Input Data:**
    *   **Avoid Piping Sensitive Data:** Do not pipe sensitive information (passwords, API keys, private data, proprietary code) into `dreampipe` unless you fully trust the configured LLM endpoint (e.g., a local Ollama instance) and understand the prompt's purpose.
    *   **Beware Indirect Prompt Injection:** Be aware that data from commands like `cat file.log` or `make` could potentially contain hidden instructions that influence the LLM's output.
2.  **Craft Prompts Carefully:**
    *   Be specific and unambiguous in your prompts.
    *   Avoid prompts that could easily be misinterpreted to generate harmful or misleading advice.
3.  **Critically Evaluate LLM Output:**
    *   **Do Not Implicitly Trust:** Always treat output from `dreampipe` (and by extension, the LLM) with skepticism. Verify important information.
    *   **Beware of Suggested Commands/Code:** If the LLM output contains shell commands or code snippets, **do not execute them blindly**. Understand what they do and the potential impact before running them manually.
4.  **Secure Secrets Management (Contextual):**
    *   While `dreampipe` doesn't generate scripts that handle secrets, if your prompts involve asking the LLM *how* to handle secrets or process data that *contains* secrets, be extremely cautious.
    *   **Never** include raw secrets directly in your `dreampipe` prompts.
5.  **Run with Least Privilege:** Execute `dreampipe` commands as a non-root user whenever possible.
6.  **Keep `dreampipe` Updated:** Install updates promptly to benefit from security patches and improvements.
7.  **Understand Your LLM:** Be aware of the capabilities, limitations, and potential biases of the configured LLM (Gemini, Ollama, Groq, etc.).

## Security Measures Implemented / Planned

The `dreampipe` project aims to incorporate the following security measures:

**Implemented (or MUST be implemented):**

*   **Clear Prompt Separation:** Internally, maintain clear separation between system instructions, user prompts, and piped-in data sent to the LLM to mitigate prompt injection risks.
*   **Prominent Security Warnings:** Include clear warnings in documentation (like this file) about the nature of LLM interactions.

**Planned / Highly Recommended (SHOULD):**

*   **Input/Output Size Limits:** Implement configurable limits to prevent basic memory exhaustion and API abuse DoS.
*   **Verbose/Debug Mode:** Offer a mode to display the exact final prompt sent to the LLM for transparency and debugging.

**Under Consideration (COULD):**

*   **Dependency Management:** Keep dependencies updated and audited.

## Disclaimer

`dreampipe` is provided "as is," without warranty of any kind. While we strive to make `dreampipe` a useful tool, the nature of interacting with LLMs means **the user bears ultimate responsibility for safe usage and for critically evaluating the output generated**. Be cautious about input data and prompts, and understand the risks involved before using `dreampipe`.
```

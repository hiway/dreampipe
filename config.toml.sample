default_provider = "ollama" # Or "gemini"
request_timeout_seconds = 60 # Applies to Ollama HTTP client too

[llms.gemini]
  api_key = "YOUR_GEMINI_API_KEY"
  # model = "gemini-2.0-flash-lite"

[llms.ollama]
  base_url = "http://localhost:11434" # Default, change if your Ollama is elsewhere
  model = "llama3" # Optional: specify a model available on your Ollama server
                   # If omitted, "llama3" from client.go will be used.